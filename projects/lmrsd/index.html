<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Pre-review to Peer review | Pitfalls of Automating Reviews using Large Language Models | Akhil Pandey Akella</title>
<meta name="keywords" content="">
<meta name="description" content="Systematically assessing scholarly works to identify novel, generalizable, and reproducible science">
<meta name="author" content="Akhil Pandey">
<link rel="canonical" href="https://akhilpandey95.github.io/projects/lmrsd/">
<meta name="google-site-verification" content="G-PNYGCP0LEP">
<link crossorigin="anonymous" href="https://akhilpandey95.github.io/assets/css/stylesheet.ee4228d3ed69c3d0066c8795680f83b12a96a25bb5d467be054337e5adf23538.css" integrity="sha256-7kIo0&#43;1pw9AGbIeVaA&#43;DsSqWolu11Ge&#43;BUM35a3yNTg=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://akhilpandey95.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://akhilpandey95.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://akhilpandey95.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://akhilpandey95.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://akhilpandey95.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://akhilpandey95.github.io/projects/lmrsd/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="stylesheet" href="https://akhilpandey95.github.io/css/extended/override.css">

      <script async src="https://www.googletagmanager.com/gtag/js?id=G-PNYGCP0LEP"></script>
      <script>
        var doNotTrack = false;
        if ( true ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-PNYGCP0LEP');
        }
      </script><meta property="og:url" content="https://akhilpandey95.github.io/projects/lmrsd/">
  <meta property="og:site_name" content="Akhil Pandey Akella">
  <meta property="og:title" content="Pre-review to Peer review | Pitfalls of Automating Reviews using Large Language Models">
  <meta property="og:description" content="Systematically assessing scholarly works to identify novel, generalizable, and reproducible science">
  <meta property="og:locale" content="en-US">
  <meta property="og:type" content="article">
    <meta property="article:section" content="projects">
    <meta property="article:published_time" content="2025-12-14T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-12-14T00:00:00+00:00">
    <meta property="og:image" content="https://akhilpandey95.github.io/img/LMRSD.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://akhilpandey95.github.io/img/LMRSD.png">
<meta name="twitter:title" content="Pre-review to Peer review | Pitfalls of Automating Reviews using Large Language Models">
<meta name="twitter:description" content="Systematically assessing scholarly works to identify novel, generalizable, and reproducible science">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Projects",
      "item": "https://akhilpandey95.github.io/projects/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Pre-review to Peer review | Pitfalls of Automating Reviews using Large Language Models",
      "item": "https://akhilpandey95.github.io/projects/lmrsd/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Pre-review to Peer review | Pitfalls of Automating Reviews using Large Language Models",
  "name": "Pre-review to Peer review | Pitfalls of Automating Reviews using Large Language Models",
  "description": "Systematically assessing scholarly works to identify novel, generalizable, and reproducible science",
  "keywords": [
    
  ],
  "articleBody": "Abstract Large Language Models are versatile general-task solvers, and their capabilities can truly assist people with scholarly peer review as \\textit{pre-review} agents, if not as fully autonomous \\textit{peer-review} agents. While incredibly beneficial, automating academic peer-review, as a concept, raises concerns surrounding safety, research integrity, and the validity of the academic peer-review process. The majority of the studies performing a systematic evaluation of frontier LLMs generating reviews across science disciplines miss the mark on addressing the alignment/misalignment of reviews along with the utility of LLM generated reviews when compared against publication outcomes such as \\textbf{Citations}, \\textbf{Hit-papers}, \\textbf{Novelty}, and \\textbf{Disruption}. This paper presents an experimental study in which we gathered ground-truth reviewer ratings from OpenReview and used various frontier open-weight LLMs to generate reviews of papers to gauge the safety and reliability of incorporating LLMs into the scientific review pipeline. Our findings demonstrate the utility of frontier open-weight LLMs as pre-review screening agents despite highlighting fundamental misalignment risks when deployed as autonomous reviewers. Our results show that all models exhibit weak correlation with human peer reviewers (0.15), with systematic overestimation bias of 3-5 points and uniformly high confidence scores (8.0-9.0/10) despite prediction errors. However, we also observed that LLM reviews correlate more strongly with post-publication metrics than with human scores, suggesting potential utility as pre-review screening tools. Our findings highlight the potential and address the pitfalls of automating peer reviews with language models. We open-sourced our dataset $D_{LMRSD}$ to help the research community expand the safety framework of automating scientific reviews.\nAuthors: Akhil Pandey Akella, Harish Varma Siravuri, Shaurya Rohtagi\nPaper: https://arxiv.org/abs/2512.22145\nCode: https://github.com/akhilpandey95/LMRSD\nHuggingFace: https://huggingface.co/datasets/akhilpandey95/LMRSD\nAcknowledgement The computing resources for this work is supported in part by the Google Cloud Research Credits Grant 331845891, and Lambda Labs Credits through the support program D1: CSC-SUPPORT-CDFF-2025-3-31.\n",
  "wordCount" : "293",
  "inLanguage": "en",
  "image":"https://akhilpandey95.github.io/img/LMRSD.png","datePublished": "2025-12-14T00:00:00Z",
  "dateModified": "2025-12-14T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Akhil Pandey"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://akhilpandey95.github.io/projects/lmrsd/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Akhil Pandey Akella",
    "logo": {
      "@type": "ImageObject",
      "url": "https://akhilpandey95.github.io/favicon.ico"
    }
  }
}
</script>
    
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      displayAlign: 'center',    /* truly center block math */
      displayIndent: '0em',      /* kill any default indent */
      "HTML-CSS": {
        styles: {'.MathJax_Preview': {visibility: 'hidden'}}
      }
    });
  </script>

  
  <script
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
    async>
  </script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://akhilpandey95.github.io/" accesskey="h" title="Akhil Pandey Akella (Alt + H)">Akhil Pandey Akella</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://akhilpandey95.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://akhilpandey95.github.io/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://akhilpandey95.github.io/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://akhilpandey95.github.io/cv/cv.pdf" title="CV">
                    <span>CV</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Pre-review to Peer review | Pitfalls of Automating Reviews using Large Language Models
    </h1>
    <div class="post-description">
      Systematically assessing scholarly works to identify novel, generalizable, and reproducible science
    </div>
    <div class="post-meta"><span title='2025-12-14 00:00:00 +0000 UTC'>December 14, 2025</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Akhil Pandey

</div>
  </header> 
<figure class="entry-cover">
        <img loading="eager" src="https://akhilpandey95.github.io/img/LMRSD.png" alt="">
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#abstract" aria-label="Abstract">Abstract</a></li>
                <li>
                    <a href="#acknowledgement" aria-label="Acknowledgement">Acknowledgement</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h3>
<p>Large Language Models are versatile general-task solvers, and their capabilities can truly assist people with scholarly peer review as \textit{pre-review} agents, if not as fully autonomous \textit{peer-review} agents. While incredibly beneficial, automating academic peer-review, as a concept, raises concerns surrounding safety, research integrity, and the validity of the academic peer-review process. The majority of the studies performing a systematic evaluation of frontier LLMs generating reviews across science disciplines miss the mark on addressing the alignment/misalignment of reviews along with the utility of LLM generated reviews when compared against publication outcomes such as \textbf{Citations}, \textbf{Hit-papers}, \textbf{Novelty}, and \textbf{Disruption}. This paper presents an experimental study in which we gathered ground-truth reviewer ratings from OpenReview and used various frontier open-weight LLMs to generate reviews of papers to gauge the safety and reliability of incorporating LLMs into the scientific review pipeline. Our findings demonstrate the utility of frontier open-weight LLMs as pre-review screening agents despite highlighting fundamental misalignment risks when deployed as autonomous reviewers. Our results show that all models exhibit weak correlation with human peer reviewers (0.15), with systematic overestimation bias of 3-5 points and uniformly high confidence scores (8.0-9.0/10) despite prediction errors. However, we also observed that LLM reviews correlate more strongly with post-publication metrics than with human scores, suggesting potential utility as pre-review screening tools. Our findings highlight the potential and address the pitfalls of automating peer reviews with language models. We open-sourced our dataset $D_{LMRSD}$ to help the research community expand the safety framework of automating scientific reviews.</p>
<blockquote>
<p>Authors: <strong>Akhil Pandey Akella</strong>, Harish Varma Siravuri, Shaurya Rohtagi</p>
</blockquote>
<blockquote>
<p>Paper: <a href="https://arxiv.org/abs/2512.22145">https://arxiv.org/abs/2512.22145</a></p>
</blockquote>
<blockquote>
<p>Code: <a href="https://github.com/akhilpandey95/LMRSD">https://github.com/akhilpandey95/LMRSD</a></p>
</blockquote>
<blockquote>
<p>HuggingFace: <a href="https://huggingface.co/datasets/akhilpandey95/LMRSD">https://huggingface.co/datasets/akhilpandey95/LMRSD</a></p>
</blockquote>
<h3 id="acknowledgement">Acknowledgement<a hidden class="anchor" aria-hidden="true" href="#acknowledgement">#</a></h3>
<p>The computing resources for this work is supported in part by the Google Cloud Research Credits Grant <strong>331845891</strong>, and Lambda Labs Credits through the support program <strong>D1: CSC-SUPPORT-CDFF-2025-3-31</strong>.</p>
<figure style="text-align: center;">
  <img src="https://lambda.ai/hubfs/lambda%20logo%202.svg" width="150" height="auto" alt="Lambda logo">
  <img src="https://www.gstatic.com/devrel-devsite/prod/v0e0f589edd85502a40d78d7d0825db8ea5ef3b99ab4070381ee86977c9168730/cloud/images/cloud-logo.svg" width="150" height="auto" alt="GCP">
</figure>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2026 <a href="https://akhilpandey95.github.io/">Akhil Pandey Akella</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>

