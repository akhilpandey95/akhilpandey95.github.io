<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Graphs, LLM&#39;s and Science of Science | Akhil Pandey</title>
<meta name="keywords" content="">
<meta name="description" content="Exploring the bridge between scientific knowledge and Large Language models">
<meta name="author" content="Akhil Pandey">
<link rel="canonical" href="https://akhilpandey95.github.io/blog/graphs-llms-and-science-of-science/">
<meta name="google-site-verification" content="UA-135077366-1">
<link crossorigin="anonymous" href="https://akhilpandey95.github.io/assets/css/stylesheet.cc07dec7dd9f28dca2ede3805b2043470261714d96bb4606b7d2b8e0b76d86f8.css" integrity="sha256-zAfex92fKNyi7eOAWyBDRwJhcU2Wu0YGt9K44Ldthvg=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://akhilpandey95.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://akhilpandey95.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://akhilpandey95.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://akhilpandey95.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://akhilpandey95.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://akhilpandey95.github.io/blog/graphs-llms-and-science-of-science/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="stylesheet" href="https://akhilpandey95.github.io/css/extended/override.css">
<meta property="og:url" content="https://akhilpandey95.github.io/blog/graphs-llms-and-science-of-science/">
  <meta property="og:site_name" content="Akhil Pandey">
  <meta property="og:title" content="Graphs, LLM&#39;s and Science of Science">
  <meta property="og:description" content="Exploring the bridge between scientific knowledge and Large Language models">
  <meta property="og:locale" content="en-US">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2024-05-18T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-05-18T00:00:00+00:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Graphs, LLM&#39;s and Science of Science">
<meta name="twitter:description" content="Exploring the bridge between scientific knowledge and Large Language models">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blog",
      "item": "https://akhilpandey95.github.io/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Graphs, LLM's and Science of Science",
      "item": "https://akhilpandey95.github.io/blog/graphs-llms-and-science-of-science/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Graphs, LLM's and Science of Science",
  "name": "Graphs, LLM\u0027s and Science of Science",
  "description": "Exploring the bridge between scientific knowledge and Large Language models",
  "keywords": [
    
  ],
  "articleBody": "Graphs and LLM’s The evolving nature of experiments in artificial intelligence and the exponential pace of scientific progress in developing domain specific large language models (LLM) elevated the use cases of language models to assist researchers in advancing scientific discovery. Conversational interfaces using Auto-regressive LLM’s such as GPT-4, LLaMA, Gemini, Claude, Mistral dominated the public discourse with immediate adoption by diverse communities. Knowledge distillation from representations of LLM’s are good priors for evaluating predictive models large for AI for Science(AI4Science) initiative and scientific discovery in the age of artificial intelligence will rely on such initiatives. Scientific discovery includes several stages and collecting the data, building the experiments, analyzing the results to come up with salient hypothesis are few of the stages that have reasonable scope to include LLM’s in the loop. Augmenting various stages of the scientific process with AI models comes with a plethora of benefits and poses risks therefore it is important to make reliability, and safety of these models a priority thereby enhancing the societal benefit of scientific discovery.\nInteresting research directions Science is an ongoing process and the rapid evolution of artificial intelligence, particularly large language models (LLMs), has profound implications for scientific discovery [4]. We need to ensure models utilized for scientific problems such as navigation in the hypothesis space of scientific data, predictive modelling on protein sequences etc must have trust and safety principles embedded within architecture considerations. To fully align with AI4Science initiatives, it is critical to prioritize reliability and safety, ensuring societal benefits. The agenda for my future research builds on the foundations of representation learning, graph theory, and transformers to build an empirical framework for accelerating scientific discovery. This research agenda transcends mere scholarly inquiry. The outcomes of my future research will focus on developing a large-scale computational framework bringing together Transformer language models (Pre-trained \u0026 Auto-regressive), Representational learning techniques (Geometric \u0026 Sequential), and uncertainty quantification approaches. This framework aims to accelerate scientific discovery and conceptually, ideas mentioned in [1], and [2] as observed in Fig. 1. provide recipes for the responsible application of AI models throughout the scientific process.\nFig 1. A generalized roadmap to unify heterogenous graphs with large language models as mentioned in [2].\nLearning meaningful representations of scientific data The foundation of effective AI support in science lies in the ability to represent complex scientific data in ways that are both meaningful and computationally tractable. This direction will investigate advanced representation learning techniques to capture the nuances and relationships inherent in scientific knowledge. Eq.1 represents the pseudo-likelihood variational framework 5. that will be useful for learning node level representations when we combine GNNs and LM’s together in Text Attributed Graphs represented by\n$$\\mathcal{G} = (V, A, s_V)$$\nwhere for all nodes $V$ and their adjacency matrix\n$$A \\in \\mathbb{R}^{|V| \\times |V|}$$ each node\n$$n \\in V$$\nis associated with a sequential text feature (sentence), giving us Eq.1\n$$log p(y_i | s_i, A) \u003e= E_{q(y_i’ | s_i’)} [log p(y_i’ | s_i, A) - log q(y_i’ | s_i’)]$$\nUncertainty Aware fused Graph-Language models for scientific discovery Quantifying uncertainty in mission critical scientific applications often brings challenges with respect to model architecture and training procedures. Building uncertainty-aware synergized graph-language models will seamlessly blend graph-based representations with language model embeddings, allowing for explicit modeling of uncertainty and supporting more robust scientific reasoning.\nThe first part of Eq.2 represents using LLM’s to obtain contextualized embeddings for text data associated with the nodes in a graph where\n$$\\mathbf{x}_i$$ is the input text sequence associated with node i,\n$$\\theta_\\text{LM}$$ are the parameters of the language model, and\n$$\\mathbf{h}_i$$ are the contextualized embeddings obtained from the language model for the input text\n$$\\mathbf{x}_i$$\n$$\\mathbf{h}_i = LM(\\mathbf{x}_i, \\theta \\text{LM})$$\n$$q(\\mathbf{z}_i) = \\mathcal{N}(\\mu_i, \\sigma_i^2)$$\nBy modeling the fused representation $\\mathbf{z}_i$ as a distribution rather than a point estimate, the model can capture uncertainty in the representations. As an under-explored concept, it would be interesting to bring various UQ estimation techniques employed for Graphs [3] onto fused graph-language models.\nFig 2. Possible directions exposed in [1] on utilizing LLM’s on graphs with varying degree of textual information\nEfficient utilization of semantic neighbors for generating scientific hypotheses Generating Scientific hypothesis is a novel task in the list of grand problems potentially addressed by AI for scientific discovery [4]. This direction will explore strategies for leveraging the rich neighborhood information in the form of semantic neighbors, citation neighbors, and knowledge neighbors within scientific literature to facilitate efficient and insightful hypotheses that will be beneficial for the research community.\nBroader Impact The broader impact of my research is to contribute towards furthering the discussion on methods to enhance scientific discovery that can potentially affect the general public, and scholarly communities. Addressing scientific novelty and and facilitating impactful knowledge discovery will save human capital, intellectual capital, time, and computational resources. My work can serve as a means to amplify calls for a robust, transparent, and trustworthy scientific environment. By advancing theoretical knowledge and practical methodologies, I aim to influence the broader scientific community’s approach to research integrity. Additionally, through my publications, I am committed to disseminating my findings and fostering a dialogue, aiming to raise awareness and encourage best practices within and beyond the academic community.\nReferences Jin, B., Liu, G., Han, C., Jiang, M., Ji, H., \u0026 Han, J. (2023). Large language models on graphs: A comprehensive survey. arXiv preprint arXiv:2312.02783. Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., \u0026 Wu, X. (2023). Unifying large language models and knowledge graphs: A roadmap. ArXiv, abs/2306.08302. Retrieved from https://api.semanticscholar.org/CorpusID:259165563 Wang, F., Liu, Y., Liu, K., Wang, Y., Medya, S., \u0026 Yu, P. S. (2024). Uncertainty in graph neural networks: A survey. arXiv preprint arXiv:2403.07185. Wang, H., Fu, T., Du, Y., Gao, W., Huang, K., Liu, Z., . . . others (2023). Scientific discovery in the age of artificial intelligence. Nature, 620(7972), 47–60. Zhao, J., Qu, M., Li, C., Yan, H., Liu, Q., Li, R., . . . Tang, J. (2022). Learning on large-scale text-attributed graphs via variational inference. arXiv preprint arXiv:2210.14709. ",
  "wordCount" : "1000",
  "inLanguage": "en",
  "datePublished": "2024-05-18T00:00:00Z",
  "dateModified": "2024-05-18T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Akhil Pandey"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://akhilpandey95.github.io/blog/graphs-llms-and-science-of-science/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Akhil Pandey",
    "logo": {
      "@type": "ImageObject",
      "url": "https://akhilpandey95.github.io/favicon.ico"
    }
  }
}
</script>
    
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      displayAlign: 'center',    /* truly center block math */
      displayIndent: '0em',      /* kill any default indent */
      "HTML-CSS": {
        styles: {'.MathJax_Preview': {visibility: 'hidden'}}
      }
    });
  </script>

  
  <script
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
    async>
  </script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://akhilpandey95.github.io/" accesskey="h" title="Akhil Pandey (Alt + H)">Akhil Pandey</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://akhilpandey95.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://akhilpandey95.github.io/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://akhilpandey95.github.io/blog/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://akhilpandey95.github.io/cv/cv.pdf" title="CV">
                    <span>CV</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://akhilpandey95.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://akhilpandey95.github.io/blog/">Blog</a></div>
    <h1 class="post-title entry-hint-parent">
      Graphs, LLM&#39;s and Science of Science
    </h1>
    <div class="post-description">
      Exploring the bridge between scientific knowledge and Large Language models
    </div>
    <div class="post-meta"><span title='2024-05-18 00:00:00 +0000 UTC'>May 18, 2024</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Akhil Pandey

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#graphs-and-llms" aria-label="Graphs and LLM&rsquo;s">Graphs and LLM&rsquo;s</a><ul>
                        <ul>
                        
                <li>
                    <a href="#interesting-research-directions" aria-label="Interesting research directions">Interesting research directions</a></li>
                <li>
                    <a href="#learning-meaningful-representations-of-scientific-data" aria-label="Learning meaningful representations of scientific data">Learning meaningful representations of scientific data</a></li>
                <li>
                    <a href="#uncertainty-aware-fused-graph-language-models-for-scientific-discovery" aria-label="Uncertainty Aware fused Graph-Language models for scientific discovery">Uncertainty Aware fused Graph-Language models for scientific discovery</a></li>
                <li>
                    <a href="#efficient-utilization-of-semantic-neighbors-for-generating-scientific-hypotheses" aria-label="Efficient utilization of semantic neighbors for generating scientific hypotheses">Efficient utilization of semantic neighbors for generating scientific hypotheses</a></li>
                <li>
                    <a href="#broader-impact" aria-label="Broader Impact">Broader Impact</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="graphs-and-llms">Graphs and LLM&rsquo;s<a hidden class="anchor" aria-hidden="true" href="#graphs-and-llms">#</a></h1>
<p>The evolving nature of experiments in artificial intelligence and the exponential pace of scientific progress in developing domain specific large language models (LLM) elevated the use cases of language models to assist researchers in advancing scientific discovery. Conversational interfaces using Auto-regressive LLM&rsquo;s such as <strong>GPT-4, LLaMA, Gemini, Claude, Mistral</strong> dominated the public discourse with immediate adoption by diverse communities. Knowledge distillation from representations of LLM&rsquo;s are good priors for evaluating predictive models large for <em>AI for Science</em>(AI4Science) initiative and scientific discovery in the age of artificial intelligence will rely on such initiatives. Scientific discovery includes several stages and collecting the data, building the experiments, analyzing the results to come up with salient hypothesis are few of the stages that have reasonable scope to include LLM&rsquo;s in the loop. Augmenting various stages of the scientific process with AI models comes with a plethora of benefits and poses risks therefore it is important to make reliability, and safety of these models a priority thereby enhancing the societal benefit of scientific discovery.</p>
<h3 id="interesting-research-directions">Interesting research directions<a hidden class="anchor" aria-hidden="true" href="#interesting-research-directions">#</a></h3>
<p>Science is an ongoing process and the rapid evolution of artificial intelligence, particularly large language models (LLMs), has profound implications for scientific discovery <strong>[4]</strong>. We need to ensure models utilized for scientific problems such as navigation in the hypothesis space of scientific data, predictive modelling on protein sequences etc must have trust and safety principles embedded within architecture considerations. To fully align with AI4Science initiatives, it is critical to prioritize reliability and safety, ensuring societal benefits. The agenda for my future research builds on the foundations of representation learning, graph theory, and transformers to build an empirical framework for accelerating scientific discovery. This research agenda transcends mere scholarly inquiry. The outcomes of my future research will focus on developing a large-scale computational framework bringing together Transformer language models (Pre-trained &amp; Auto-regressive), Representational learning techniques (Geometric &amp; Sequential), and uncertainty quantification approaches. This framework aims to accelerate scientific discovery and conceptually, ideas mentioned in <strong>[1]</strong>, and <strong>[2]</strong> as observed in Fig. 1. provide recipes for the responsible application of AI models throughout the scientific process.</p>
<p><img alt="image" loading="lazy" src="https://akhilpandey95.github.io/img/unifying_llms_graphs.png"></p>
<blockquote>
<p>Fig 1. A generalized roadmap to unify heterogenous graphs with large language models as mentioned in <strong>[2]</strong>.</p></blockquote>
<h3 id="learning-meaningful-representations-of-scientific-data">Learning meaningful representations of scientific data<a hidden class="anchor" aria-hidden="true" href="#learning-meaningful-representations-of-scientific-data">#</a></h3>
<p>The foundation of effective AI support in science lies in the ability to represent complex scientific data in ways that are both meaningful and computationally tractable. This direction will investigate advanced representation learning techniques to capture the nuances and relationships inherent in scientific knowledge. Eq.1 represents the pseudo-likelihood variational framework 5. that will be useful for learning node level representations when we combine GNNs and LM&rsquo;s together in Text Attributed Graphs represented by</p>
<p>$$\mathcal{G} = (V, A, s_V)$$</p>
<p>where for all nodes $V$ and their adjacency matrix</p>
<p>$$A \in \mathbb{R}^{|V| \times |V|}$$ each node</p>
<p>$$n \in V$$</p>
<p>is associated with a sequential text feature (sentence), giving us Eq.1</p>
<p>$$log p(y_i | s_i, A) &gt;= E_{q(y_i&rsquo; | s_i&rsquo;)} [log p(y_i&rsquo; | s_i, A) - log q(y_i&rsquo; | s_i&rsquo;)]$$</p>
<h3 id="uncertainty-aware-fused-graph-language-models-for-scientific-discovery">Uncertainty Aware fused Graph-Language models for scientific discovery<a hidden class="anchor" aria-hidden="true" href="#uncertainty-aware-fused-graph-language-models-for-scientific-discovery">#</a></h3>
<p>Quantifying uncertainty in mission critical scientific applications often brings challenges with respect to model architecture and training procedures. Building uncertainty-aware synergized graph-language models will seamlessly blend graph-based representations with language model embeddings, allowing for explicit modeling of uncertainty and supporting more robust scientific reasoning.</p>
<p>The first part of Eq.2 represents using LLM&rsquo;s to obtain contextualized embeddings for text data associated with the nodes in a graph where</p>
<p>$$\mathbf{x}_i$$ is the input text sequence associated with node <em>i</em>,</p>
<p>$$\theta_\text{LM}$$ are the parameters of the language model, and</p>
<p>$$\mathbf{h}_i$$ are the contextualized embeddings obtained from the language model for the input text</p>
<p>$$\mathbf{x}_i$$</p>
<p>$$\mathbf{h}_i = LM(\mathbf{x}_i, \theta \text{LM})$$</p>
<p>$$q(\mathbf{z}_i) = \mathcal{N}(\mu_i, \sigma_i^2)$$</p>
<p>By modeling the fused representation $\mathbf{z}_i$ as a distribution rather than a point estimate, the model can capture uncertainty in the representations. As an under-explored concept, it would be interesting to bring various UQ estimation techniques employed for Graphs <strong>[3]</strong> onto fused graph-language models.</p>
<p><img alt="image" loading="lazy" src="https://akhilpandey95.github.io/img/graphs-LLMs.png"></p>
<blockquote>
<p>Fig 2. Possible directions exposed in [1] on utilizing LLM&rsquo;s on graphs with varying degree of textual information</p></blockquote>
<h3 id="efficient-utilization-of-semantic-neighbors-for-generating-scientific-hypotheses">Efficient utilization of semantic neighbors for generating scientific hypotheses<a hidden class="anchor" aria-hidden="true" href="#efficient-utilization-of-semantic-neighbors-for-generating-scientific-hypotheses">#</a></h3>
<p>Generating Scientific hypothesis is a novel task in the list of grand problems potentially addressed by AI for scientific discovery <strong>[4]</strong>. This direction will explore strategies for leveraging the rich neighborhood information in the form of semantic neighbors, citation neighbors, and knowledge neighbors within scientific literature to facilitate efficient and insightful hypotheses that will be beneficial for the research community.</p>
<h3 id="broader-impact">Broader Impact<a hidden class="anchor" aria-hidden="true" href="#broader-impact">#</a></h3>
<p>The broader impact of my research is to contribute towards furthering the discussion on methods to enhance scientific discovery that can potentially affect the general public, and scholarly communities. Addressing scientific novelty and and facilitating impactful knowledge discovery will save human capital, intellectual capital, time, and computational resources. My work can serve as a means to amplify calls for a robust, transparent, and trustworthy scientific environment. By advancing theoretical knowledge and practical methodologies, I aim to influence the broader scientific community&rsquo;s approach to research integrity. Additionally, through my publications, I am committed to disseminating my findings and fostering a dialogue, aiming to raise awareness and encourage best practices within and beyond the academic community.</p>
<h3 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h3>
<ol>
<li>Jin, B., Liu, G., Han, C., Jiang, M., Ji, H., &amp; Han, J. (2023). Large language models on graphs: A comprehensive survey. arXiv preprint arXiv:2312.02783.</li>
<li>Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., &amp; Wu, X. (2023). Unifying large language models and knowledge graphs: A roadmap. ArXiv, abs/2306.08302. Retrieved from <a href="https://api.semanticscholar.org/CorpusID:259165563">https://api.semanticscholar.org/CorpusID:259165563</a></li>
<li>Wang, F., Liu, Y., Liu, K., Wang, Y., Medya, S., &amp; Yu, P. S. (2024). Uncertainty in graph neural networks: A survey. arXiv preprint arXiv:2403.07185.</li>
<li>Wang, H., Fu, T., Du, Y., Gao, W., Huang, K., Liu, Z., . . . others (2023). Scientific discovery in the age of artificial intelligence. Nature, 620(7972), 47–60.</li>
<li>Zhao, J., Qu, M., Li, C., Yan, H., Liu, Q., Li, R., . . . Tang, J. (2022). Learning on large-scale text-attributed graphs via variational inference. arXiv preprint arXiv:2210.14709.</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://akhilpandey95.github.io/">Akhil Pandey</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>

